# Pokemon_challenge

<img src="https://wallpapers.com/images/hd/legendary-pokemon-pictures-7yo7x0f1l2b2tu0r.jpg" width="500" height="300" alt="legendaries">

Pokemon Challenge for the course Deep Learning Lab @ USI

Rules of the challenge:

Gotta catch 'em all! ...But give priority to the legendaries.

F1-score is usually the measure of choice for imbalanced datasets; however in this case we particularly want to avoid not "catching" legendaries. They're so rare, you might not have any more chances to catch 'em if they flee...

In ML terms, we give recall more importance than precision for the task.

F2-score (i.e., F-β -score with  β=2) is hence used as the main evaluation metric for your model.

TAs achieved a F2-score of 0.80. Can you beat them?!
